{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-19T19:14:22.083453Z",
     "start_time": "2025-04-19T19:14:22.079475Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T19:14:22.150328Z",
     "start_time": "2025-04-19T19:14:22.143714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_csv_files(file_paths, output_path='merged_data.csv'):\n",
    "    \"\"\"\n",
    "    Merge multiple CSV files with the same format into a single CSV file\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths to the CSV files to merge\n",
    "    output_path (str): Path where the merged CSV file will be saved\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The merged dataframe\n",
    "    \"\"\"\n",
    "    # Check if file_paths is empty\n",
    "    if not file_paths:\n",
    "        raise ValueError(\"No files provided for merging\")\n",
    "\n",
    "    # List to store individual dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Read each CSV file and append to the list\n",
    "    for file in file_paths:\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"Warning: File {file} does not exist and will be skipped\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            dataframes.append(df)\n",
    "            print(f\"Successfully read {file} with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {str(e)}\")\n",
    "\n",
    "    # Check if any dataframes were successfully loaded\n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No valid CSV files could be read\")\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the merged dataframe to a CSV file\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged data saved to {output_path}\")\n",
    "\n",
    "    return merged_df"
   ],
   "id": "279bf381612f9f14",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T19:14:22.205441Z",
     "start_time": "2025-04-19T19:14:22.174789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "\n",
    "# List your CSV files here\n",
    "files_to_merge = [\n",
    "    \"riasec_survey_data_2025-04-17.csv\",\n",
    "    \"riasec_survey_data_2025-04-18.csv\",\n",
    "    \"riasec_survey_data_2025-04-18 2.csv\"\n",
    "]\n",
    "\n",
    "# Merge the files\n",
    "merged_data = merge_csv_files(files_to_merge, \"dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(\"\\nPreview of merged data:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Print some statistics about the merged data\n",
    "print(f\"\\nTotal number of rows in merged data: {merged_data.shape[0]}\")\n",
    "print(f\"Total number of columns in merged data: {merged_data.shape[1]}\")"
   ],
   "id": "22a9818b84644423",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read riasec_survey_data_2025-04-17.csv with 128 rows and 34 columns\n",
      "Successfully read riasec_survey_data_2025-04-18.csv with 172 rows and 34 columns\n",
      "Successfully read riasec_survey_data_2025-04-18 2.csv with 23 rows and 34 columns\n",
      "Merged data saved to dataset.csv\n",
      "\n",
      "Preview of merged data:\n",
      "                name student_id                 timestamp  \\\n",
      "0   Aytaç Eren Cirit      321.0  2025-04-17T15:34:42.836Z   \n",
      "1      Hüseyin Demir      273.0  2025-04-17T15:37:15.063Z   \n",
      "2  Erdem Ruhi Baysal      286.0  2025-04-17T15:37:53.382Z   \n",
      "3          Mert Yuva      300.0  2025-04-17T15:39:48.807Z   \n",
      "4       Zeren Çalgın     1309.0  2025-04-17T15:40:19.259Z   \n",
      "\n",
      "                     raw_response  q1  q2  q3  q4  q5  q6  ...  q21  q22  q23  \\\n",
      "0  221121122122222121211111211111   1   1   0   0   1   0  ...    0    0    0   \n",
      "1  121121221111211122212112212111   0   1   0   0   1   0  ...    1    0    0   \n",
      "2  221221222211211122212212222122   1   1   0   1   1   0  ...    1    1    0   \n",
      "3  221121122211111111112212221211   1   1   0   0   1   0  ...    1    1    0   \n",
      "4  211122121222221122111112111121   1   0   0   0   1   1  ...    0    0    0   \n",
      "\n",
      "   q24  q25  q26  q27  q28  q29  q30  \n",
      "0    0    1    0    0    0    0    0  \n",
      "1    1    1    0    1    0    0    0  \n",
      "2    1    1    1    1    0    1    1  \n",
      "3    1    1    1    0    1    0    0  \n",
      "4    1    0    0    0    0    1    0  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Total number of rows in merged data: 323\n",
      "Total number of columns in merged data: 34\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
